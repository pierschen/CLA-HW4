{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Visual Robot Collision Identification\n",
                "\n",
                "We are deploying a Kuka robot in a factory, and we want to implement a remote visual monitoring system. Part of this system includes automatic identification of collisions. We will train a machine learning model on image data to build this system. We've provided some code from previous assignments to facilitate this task.\n",
                "\n",
                "**You should download this notebook and complete it on Colab or another platform that can access GPU hardware. For submission, please attach the notebook printout to your PDF submission on Gradescope, and also re-upload the completed notebook with outputs here.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pybullet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import time\n",
                "import pybullet as p\n",
                "import numpy as np\n",
                "\n",
                "from matplotlib import pyplot as plt\n",
                "import matplotlib.image as mpl_img\n",
                "from tqdm import tqdm\n",
                "from PIL import Image\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.optim import lr_scheduler\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "from torchvision.models import resnet18, ResNet18_Weights\n",
                "from torch.utils.data import Dataset, DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up the simulation\n",
                "sim_id = p.connect(p.DIRECT)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PyBullet has a lot of built-in data (e.g., robor models), so let's get access to it\n",
                "import pybullet_data\n",
                "p.setAdditionalSearchPath(pybullet_data.getDataPath())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load up the robots!\n",
                "p.resetSimulation()\n",
                "plane_id=p.loadURDF('plane.urdf',\n",
                "            physicsClientId=sim_id)\n",
                "robot_id=p.loadURDF(\"kuka_iiwa/model.urdf\",\n",
                "            basePosition=[0,0,0],\n",
                "            baseOrientation=p.getQuaternionFromEuler([0,0,0]),\n",
                "            useFixedBase=True,\n",
                "            physicsClientId=sim_id,\n",
                "            globalScaling=1,\n",
                "            flags=p.URDF_USE_IMPLICIT_CYLINDER)\n",
                "cube_id=p.loadURDF('cube.urdf',\n",
                "            basePosition=[0.5, 0, 0.5],\n",
                "            physicsClientId=sim_id,\n",
                "            globalScaling=0.3)\n",
                "sphere_id=p.loadURDF('sphere2.urdf',\n",
                "            basePosition=[0, 0.5, 0.5],\n",
                "            physicsClientId=sim_id,\n",
                "            globalScaling=0.3)\n",
                "p.getNumBodies()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def is_collision():\n",
                "    p.performCollisionDetection(physicsClientId=sim_id)\n",
                "    all_contact_points = [cp for cp in p.getContactPoints(bodyA=robot_id) \\\n",
                "                          if cp[1] != plane_id and cp[2] != plane_id and cp[8] \u003c 0]\n",
                "    # cp[1] is first collision object, cp[2] is second collision object\n",
                "    # cp[8] is collision distance, where NEGATIVE value indicates penetration (pos value is separation)\n",
                "    return len(all_contact_points) \u003e 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "JOINT_LIMITS = np.array([np.pi * 3/4, np.pi * 2/3, np.pi * 3/4, np.pi * 2/3, np.pi * 3/4, np.pi * 2/3, np.pi * 3/4])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 1: Model Selection (4 pts)\n",
                "\n",
                "We will be using a pre-trained ResNet-18 model, which is a type of convolutional neural network. Briefly answer the following:\n",
                "* Why is a convolutional neural network a good choice for this task?\n",
                "* Why is a pre-trained model a good choice for this task?\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: Data Collection (8 pts)\n",
                "\n",
                "We will generate training data by collecting 1000 images of robots in various collision statuses. We can do so by repeating the following steps:\n",
                "* Sample a random configuration within joint limits.\n",
                "* Find its collision status using `is_collision()`.\n",
                "* Generate and store the rgb image using `show_image()` (needs to be amended).\n",
                "\n",
                "The images should be saved in a folder called ``robot_imgs``, with file name formats ``pose{sample_number}_{collision_status}.png``, where ``collision_status`` is 1 for collision, 0 for no collision. See below for proposed directory format.\n",
                "\n",
                "```\n",
                "robot_imgs/\n",
                "  pose0_1.png\n",
                "  pose1_1.png\n",
                "  pose2_1.png\n",
                "  pose3_0.png\n",
                "  pose4_0.png\n",
                "  pose5_1.png\n",
                "  pose6_0.png\n",
                "```\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run this if you need to regenerate the images\n",
                "import shutil\n",
                "if os.path.exists('robot_imgs'):\n",
                "    shutil.rmtree('robot_imgs')\n",
                "os.makedirs('robot_imgs', exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def showImage(img_idx, collision_status, cameraPos=[2, 2, 2]):\n",
                "    # Let's take some images, as a sanity check:\n",
                "    viewMatrix = p.computeViewMatrix(\n",
                "                cameraEyePosition=cameraPos,\n",
                "                cameraTargetPosition=[0, 0, 0],\n",
                "                cameraUpVector=[0, 0, 1])\n",
                "    projectionMatrix = p.computeProjectionMatrixFOV(\n",
                "                fov=60.0,\n",
                "                aspect=1.0,\n",
                "                nearVal=0.1,\n",
                "                farVal=10)\n",
                "    width, height, rgbImg, depthImg, segImg = p.getCameraImage(\n",
                "                width=512,\n",
                "                height=512,\n",
                "                viewMatrix=viewMatrix,\n",
                "                projectionMatrix=projectionMatrix)\n",
                "\n",
                "    # TODO: Save the image in folder structure as shown above.\n",
                "    # HINT: use matplotlib.image (already imported as mpl_img)\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Sample and save 1000 images of robot configurations and their collision status\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 3: Dataset Class (10 pts)\n",
                "\n",
                "We will be using PyTorch to train a model. We need to have a ``Dataset`` subclass, which gives data to PyTorch in the form of tuples ``(image, label)``. We also want an option to split the images into train and test sets, which we can do by specifying `desired_indices` as the training images. Feel free to read this tutorial (from which much of the code in this assignment was adopted) for help: [PyTorch DataLoading](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
                "\n",
                "Complete the main loop in the ``load_all_images()`` function in the ``RobotCollisionDataset`` class below by performing the following:\n",
                "\n",
                "* Retrieve each image with index in `desired_indices`.\n",
                "* Convert the image to a tensor and ensure that its dimensions are `(3,512,512)`. [`torch.from_numpy()`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) and [`torch.permute()`](https://pytorch.org/docs/stable/generated/torch.permute.html) may be useful here.\n",
                "* Append the tensor to the `images` list and the corresponding collision status (1/0) to the `labels` list."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RobotCollisionDataset(Dataset):\n",
                "    \"\"\"Face Landmarks dataset.\"\"\"\n",
                "    def __init__(self, root_dir, desired_indices):\n",
                "        \"\"\"\n",
                "        Arguments:\n",
                "            root_dir (string): Directory with all the images.\n",
                "        \"\"\"\n",
                "        self.root_dir = root_dir\n",
                "        self.desired_indices = desired_indices\n",
                "        self.images, self.labels = self.load_all_images()\n",
                "\n",
                "        self.transform = transforms.Compose([\n",
                "            transforms.Normalize((201, 212, 230), (42, 33, 23)),\n",
                "            transforms.Resize((224, 224))\n",
                "        ])\n",
                "\n",
                "    def load_all_images(self):\n",
                "        \"\"\"\n",
                "        Creates:\n",
                "        -\u003e self.images: contains robot images from self.root_dir\n",
                "        -\u003e self.labels: self.labels[i] = 1 if self.images[i] depicts a collision, 0 otherwise\n",
                "        \"\"\"\n",
                "        images = list()\n",
                "        labels = list()\n",
                "        assert os.path.exists(self.root_dir)\n",
                "\n",
                "        for filename in os.listdir(self.root_dir):\n",
                "            # TODO: Load all images from file directory\n",
                "            pass\n",
                "\n",
                "        assert len(labels) == len(images)\n",
                "        return images, labels\n",
                "\n",
                "    # Thanks https://stackoverflow.com/a/7769424\n",
                "    def load_image(self, infilename) :\n",
                "        img = Image.open(infilename)\n",
                "        img.load()\n",
                "        data = np.asarray(img, dtype=\"float32\")\n",
                "        return data\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.labels)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        if torch.is_tensor(idx):\n",
                "          idx = idx.tolist()\n",
                "        return self.transform(self.images[idx]), self.labels[idx]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 4: Loading the Data and Model (6 pts)\n",
                "\n",
                "Now we can create our dataset and store it in two `RobotCollisionDataset` objects. First define `train_dataset` containing 900 images, and `val_dataset` containing the remaining 100 images. This should only require a couple lines of code.\n",
                "\n",
                "Next, we will load a pre-trained ResNet model. To use it for our collision detection task, we need to ensure that the model has the correct output layer dimensionality. Recall that the output layer for a neural network is the probability distribution over categories. Natively, ResNet has 1000 dimensions in the output layer because it was trained for a 1000-category classification task.\n",
                "\n",
                "Load the `resnet18` model with default weights into a variable called `model` and change its dimensionality as necessary. This should only require a couple lines of code. This tutorial may be helpful: [Transfer Learning for Computer Vision](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Create train and validation datasets\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Load and adjust a pre-trained model\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 5: Training the Model (4 pts)\n",
                "\n",
                "The last function we need to write is one that will train and validate the model. We have a partial implementation of `train_model()` below. Complete the loop portion that performs prediction and obtains a loss on an input. Additionally, if the current `phase` is `'train'`, you will need to perform an optimization step on the model (this second step would not be done if `phase` is `'val'`).\n",
                "\n",
                "Note that this function essentially replicates the example shown in the [Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) tutorial. You are free to replicate any code from there to complete the implementation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=25, device='cuda'):\n",
                "    since = time.time()\n",
                "    best_model_params_path = 'best_model_params.pt'\n",
                "    torch.save(model.state_dict(), best_model_params_path)\n",
                "    best_acc = 0.0\n",
                "\n",
                "    train_losses = list()\n",
                "    train_accs = list()\n",
                "    val_losses = list()\n",
                "    val_accs = list()\n",
                "\n",
                "    for epoch in range(num_epochs):\n",
                "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
                "        print('-' * 10)\n",
                "\n",
                "        # Each epoch has a training and validation phase\n",
                "        for phase in ['train', 'val']:\n",
                "            if phase == 'train':\n",
                "                model.train()  # Set model to training mode\n",
                "            else:\n",
                "                model.eval()   # Set model to evaluate mode\n",
                "\n",
                "            running_loss = 0.0\n",
                "            running_corrects = 0\n",
                "\n",
                "            # Iterate over data\n",
                "            for inputs, labels in tqdm(dataloaders[phase]):\n",
                "                inputs = inputs.to(device)\n",
                "                labels = labels.to(device)\n",
                "\n",
                "                # zero the parameter gradients\n",
                "                optimizer.zero_grad()\n",
                "\n",
                "                # TODO: Obtain model prediction and loss on inputs\n",
                "                # If in training phase, compute gradients and perform optimization step\n",
                "                with torch.set_grad_enabled(phase == 'train'):\n",
                "                    pass\n",
                "\n",
                "                # statistics\n",
                "                running_loss += loss.item() * inputs.size(0)\n",
                "                running_corrects += torch.sum(preds == labels.data)\n",
                "\n",
                "            if phase == 'train':\n",
                "                scheduler.step()\n",
                "\n",
                "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
                "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
                "\n",
                "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
                "\n",
                "            if phase == 'train':\n",
                "                train_losses.append(epoch_loss)\n",
                "                train_accs.append(epoch_acc)\n",
                "            else:\n",
                "                val_losses.append(epoch_loss)\n",
                "                val_accs.append(epoch_acc)\n",
                "\n",
                "            # deep copy the model\n",
                "            if phase == 'val' and epoch_acc \u003e best_acc:\n",
                "                best_acc = epoch_acc\n",
                "                torch.save(model.state_dict(), best_model_params_path)\n",
                "\n",
                "        print()\n",
                "\n",
                "    time_elapsed = time.time() - since\n",
                "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
                "    print(f'Best val Acc: {best_acc:4f}')\n",
                "\n",
                "    # load best model weights\n",
                "    model.load_state_dict(torch.load(best_model_params_path))\n",
                "    return model, train_losses, train_accs, val_losses, val_accs"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 6: Putting Everything Together (8 pts)\n",
                "\n",
                "Now we are ready to put everything together. The following code sets up the required components (model, criterion, optimizer, scheduler) and then runs the training function that you completed above. There are also some parameters, e.g. learning rate and number of epochs, that you can experiment with after verifying initial success.\n",
                "\n",
                "**NOTE: Set your runtime hardware to ``T4 GPU`` only when you are ready to train the full model. Do not do so before that, or you will risk using up your GPU quota. It takes almost two hours to train on CPU, but only about five minutes on GPU.**\n",
                "\n",
                "Run the provided code, and address the prompts below.\n",
                "\n",
                "1. Use ``plot_losses()`` to plot the training and validation losses. Describe your observations and how they indicate that our learning task is successful (or failed).\n",
                "\n",
                "2. Use ``visualize_model()`` to see some images along with their predictions. Do the predictions appear mostly correct? Do you see any failure cases?\n",
                "\n",
                "3. Experiment with changing the learning rate and number of epochs. You can just try a lower and a higher value for each parameter separately. Comment on changes in model performance.\n",
                "\n",
                "4. Experiment with loading a ResNet model that isn't pre-trained. Comment on changes in model performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "learning_rate = 0.001\n",
                "num_epochs = 25\n",
                "\n",
                "data_loader_train = DataLoader(train_dataset,\n",
                "                            batch_size=64, shuffle=True)\n",
                "data_loader_val = DataLoader(val_dataset,\n",
                "                            batch_size=64, shuffle=True)\n",
                "dataloaders = {'train': data_loader_train,\n",
                "               'val': data_loader_val}\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "model = model.to(device)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "# Observe that all parameters are being optimized\n",
                "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
                "# Decay LR by a factor of 0.1 every 7 epochs\n",
                "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "model, train_losses, train_accs, val_losses, val_accs = train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs, device=device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_losses(train_losses, val_losses):\n",
                "    plt.plot(train_losses, label='train')\n",
                "    plt.plot(val_losses, label='val')\n",
                "    plt.legend()\n",
                "    plt.xlabel('epoch')\n",
                "    plt.ylabel('loss')\n",
                "    plt.show()\n",
                "\n",
                "def imshow(inp, title=None):\n",
                "    \"\"\"Display image for Tensor.\"\"\"\n",
                "    inp = inp.numpy().transpose((1, 2, 0))\n",
                "    mean = np.array([201/255, 212/255, 230/255])\n",
                "    std = np.array([42/255, 33/255, 23/255])\n",
                "    inp = std * inp + mean\n",
                "    inp = np.clip(inp, 0, 1)\n",
                "    plt.imshow(inp)\n",
                "    if title is not None:\n",
                "        plt.title(title)\n",
                "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
                "\n",
                "def visualize_model(model, dataloaders, num_images=6, class_names={0:'free', 1:'collision'}):\n",
                "    was_training = model.training\n",
                "    model.eval()\n",
                "    images_so_far = 0\n",
                "    fig = plt.figure()\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
                "            inputs = inputs.to(device)\n",
                "            labels = labels.to(device)\n",
                "\n",
                "            outputs = model(inputs)\n",
                "            _, preds = torch.max(outputs, 1)\n",
                "\n",
                "            for j in range(inputs.size()[0]):\n",
                "                images_so_far += 1\n",
                "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
                "                ax.axis('off')\n",
                "                ax.set_title(f'predicted: {class_names[preds[j].item()]}; actual: {class_names[labels[j].item()]}')\n",
                "                imshow(inputs.cpu().data[j])\n",
                "\n",
                "                if images_so_far == num_images:\n",
                "                    model.train(mode=was_training)\n",
                "                    return\n",
                "        model.train(mode=was_training)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_losses(train_losses, val_losses)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "visualize_model(model, dataloaders)"
            ]
        }
    ]
}
